---
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    toc_depth: 3
    fig_width: 5
vignette: >
  %\VignetteIndexEntry{cloudBiocWorkshop}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding[utf8]{inputenc}
---
# Cloud-scale genomic data science with Bioconductor

## Abstract

Bioconductor's approach to the analysis of genome-scale assays is
rooted in commitments to the use of self-describing data objects 
representing genomic assays and annotation.  Analysis tools and workflows
based on these objects have proven effective in a large
number of scientific projects and publications.

The dominant model for utilization of Bioconductor to date 
involves a locally controlled deployment of R and 
Bioconductor/CRAN packages in an essentially closed
storage and execution environment.

New approaches to federated
elastic computing with lab-resident or commercial cloud
environments provide opportunities for inference on questions
of vast scope.  This workshop is devoted to understanding how
to leverage Bioconductor's strengths
in seizing these new opportunities.  Special attention is devoted
to how
programming and reporting
patterns familiar from two decades of Bioconductor development
and use can be retained, or must change, in cloud-scale genomic
data science.

Our approach will be a mix of lecture and hands-on programming
with Rstudio Cloud.  We will learn how the restfulSE and BiocOncoTK
packages work with HDF Scalable Data Service and Google BigQuery
to provide immediate interactive access to a compendium of 181000
human transcriptomics experiments, and to the PanCancer Atlas.
We will also learn how to couple Docker containers with formal
workflows in CWL and WDL to achieve sharable reproducible analyses
with nearly zero configuration.  

## Pre-requisites

* Basic knowledge of R syntax
* Familiarity with the SummarizedExperiment class
* Familiarity with one or more of TCGA, GTEx, BigQuery
* Familiarity with docker containers is not required but a running docker installation will be useful

## Workshop Participation

Students should have a laptop and be prepared to execute
specific commands to load packages and
evaluate functions.  It will be helpful to have a Google identity
that may be necessary to work with BigQuery.

## _R_ / _Bioconductor_ packages used

DelayedArray, restfulSE, rhdf5client, BiocOncoTK, 
htxcomp (github/vjcitn), TxRegInfra

## Time outline

Approximate timings for sections of workshop

| Activity                     | Time |
|------------------------------|------|
| Review of Bioconductor software and data structures | 10m  |
| DelayedArray concepts          | 5m  |
| Exercises with htxcomp and the HDF Scalable Data Service | 10m  |
| Exercises with PanCancer Atlas and Google BigQuery | 10m |
| Docker and CWL/WDL with Dockstore.org | 10m |

## Workshop goals and objectives

Goals:

* Develop an appreciation of strengths and limitations
of Bioconductor's approach
to structure and annotation of genome-scale data as scope
of data grows to cloud scale

* Learn about alternatives to "all-in-memory" models of
computing in R, and how Bioconductor has used such alternatives
in the local computing model
(e.g., external SQLite databases, local HDF5 serialization,
API to remote services)

* Obtain experience using Bioconductor
methods and tools with data and annotation that are cloud-scale

* Develop an appreciation of threats to reliability and predictable
costs that arise when working with commercial cloud computing

Objectives:

* Use rhdf5client to interact with matrix data in HDF Scalable Data Service

* Use BiocOncoTK to interrogate multiomic PanCancer atlas data in Google BigQuery

* Understand the role of Docker containers and formal workflow
expression in establishing reproducible and shareable large
scale analyses 

## Review of Bioconductor software and data structures (10min)

Bioconductor uses an approach to object-oriented
programming to help control complexity of programming
in the domain of genome-scale data science.

We will illustrate the basic ideas by using a
catalog of features of the human genome.

```{r setup,echo=FALSE,results="hide"}
curatedTCGAData = function(...) {
 suppressMessages({ curatedTCGAData::curatedTCGAData(...) })
 }
library = function (..., silent=TRUE)
{
  libstats = function(inisess, newsess) {
   inibase = inisess$basePkgs  # unchanging?
   inioth = names(inisess$otherPkgs)
   newbase = newsess$basePkgs
   newoth = names(newsess$otherPkgs)
   iniatt = length(unique(c(inibase,inioth)))
   newatt = length(unique(c(newbase,newoth)))
   addatt = newatt-iniatt
   inilo = names(inisess$loadedOnly)
   newlo = names(newsess$loadedOnly)
   addlo = length(setdiff(newlo, inilo))
   c(addatt=addatt, addlo=addlo)
  }
      inisess = sessionInfo()
      suppressPackageStartupMessages({
          libdata = base::library(..., quietly=TRUE)
          newsess = sessionInfo()
          lstats = libstats(inisess = inisess, newsess = newsess)
          if (!silent) message(sprintf("%d/%d packages newly attached/loaded, see sessionInfo() for details.", 
              lstats["addatt"], lstats["addlo"]))
          invisible(NULL)
      })
}
library(curatedTCGAData)
library(rhdf5client)
```

### The S4 classes `EnsDb` and `GRanges`

```{r lktxdb}
library(EnsDb.Hsapiens.v79)
EnsDb.Hsapiens.v79
```

The object named `EnsDb.Hsapiens.v79` mediates access to
a SQLite database that contains information on the
Ensembl definitions of genes for reference build
hg38.  This object is an instance of a class:
```{r lkcl}
class(EnsDb.Hsapiens.v79)
```
Formal methods are defined for this class:
```{r lkme}
methods(class=class(EnsDb.Hsapiens.v79))
```
Let's try the `genes` method.
```{r lkggg}
genes79 = genes(EnsDb.Hsapiens.v79)
genome(genes79)[1]
class(genes79)
head(genes79[,1:3])
```

Basic R language elements are given new 
meaning when applied to structures like `GRanges`.
Here we use `$` to obtain one of the fields
of metadata about genes.  The operation returns
a vector that we summarize using basic R
functions.

```{r lkso}
sort(table(genes79$gene_biotype),decreasing=TRUE)[1:6]
```

`dplyr` idioms can be used with some help (and this may
become more straightforward over time):
```{r dodp}
library(dplyr)
library(magrittr)
as.data.frame(mcols(genes79)) %>% 
  select(gene_name, gene_biotype) %>%
  filter(gene_biotype == "ribozyme")
```

`tibble` representations have pleasant summaries:
```{r lkti}
library(tibble)
as.tibble(genes79)
```

### Finding and visualizing genomic elements in a specified chromosomal region

`GRanges` are easy to construct and can be used to
query genomes.  Here we deal with three problems related
to genome region specification.  We start with a
region specified using coordinates from
reference build hg19 (GRCh37).  We use UCSC's
liftOver utility to convert to GRCh38 (hg38).  We
finish by converting the chromosome annotation to
that used by Ensembl.

```{r convert}
myRange = GRanges("chr10", IRanges(37.45e6, 37.8e6))
myRange
library(rtracklayer)
ch = import.chain(system.file("vignettes/hg19ToHg38.over.chain", 
  package="BiocCloudws"))
myr38 = liftOver(myRange, ch)[[1]]
library(GenomeInfoDb)
genome(myr38) = "GRCh38"
seqlevelsStyle(myr38) = "Ensembl"
myr38
```

It is easy to find 'gene-level' elements using `subsetByOverlaps`:
```{r getgl}
els = subsetByOverlaps(genes79, myr38)
as.tibble(els)
```

To get a quick view of the layout of these elements on
their chromosome, we can use Gviz:
```{r getgv}
library(survival)
library(Gviz)
options(ucscChromosomeNames=FALSE)
plotTracks(list(GenomeAxisTrack(), 
  GeneRegionTrack(els, gene=els$symbol)), showId=TRUE)
```

There are many options available to enhance this display.
An important task for this region would
be to distinguish exons and introns.
See the Gviz vignette for details.


## DelayedArray concepts (5min)

Our interest in cloud-scale computing methods
arises in part from desire to analyze very large
data sets with computers that have relatively small
endowments of random access memory.  The most common
methods of working with R assume that all data are
resident in memory and can be addressed directly.

### Acquisition of breast cancer RNA-seq data from TCGA

In this section we will construct two representations of
RNA-seq data for breast cancer tumors collected in TCGA.
First we use `curatedTCGAData` to obtain a standard in-memory
representation in a SummarizedExperiment.
```{r dobr,results="hide"}
library(curatedTCGAData)
brMAE = curatedTCGAData("BRCA", "RNASeq2GeneNorm", dry.run=FALSE)
```
```{r contin}
brexp = experiments(brMAE)[[1]] # should use name
colnames(brexp) = substr(colnames(brexp),1,12) # need to shorten
cd = colData(brMAE)[colnames(brexp),]
colData(brexp) = cd
brexp
```
We estimate its size in RAM.
```{r lkram}
library(SummarizedExperiment) # assay
object.size(assay(brexp))
```
This is not particularly large, but in certain applications
it is advantageous to have tight control
over the memory consumption required for an analysis.  In
this form we have no choice -- either the complete dataset
is in memory or it is not and cannot be accessed without
loading it in its entirety.

### Exporting the expression data to HDF5

Now we develop a representation on disk.  We use
the HDF5 data format as it is well-established as
a tool for managing numerical data in
scientific computing.
```{r dohdf5}
library(HDF5Array)
saveHDF5SummarizedExperiment(brexp, "brexpHDF5", replace=TRUE)
```
We named the HDF5 repository for the data `brexpHDF5`; this 
is in fact a folder created in the current working directory.
Its contents are a SummarizedExperiment 'shell' in RDS format,
and the HDF5 matrix representation of the RNA-seq quantifications.
```{r lkfol}
dir("brexpHDF5")
```

### Using the on-disk HDF5 representation

We use a loading function to retrieve the
new SummarizedExperiment instance.  Its
memory consumption is independent of the
dimensions of the assay matrix.
```{r lkmem2}
brextern = loadHDF5SummarizedExperiment("brexpHDF5")
assay(brextern)
object.size(assay(brextern))
```

Targeted queries to the HDF5 store are rapidly resolved.

```{r doexpl,fig.height=6}
par(las=2, mar=c(18,4,3,3))
boxplot(split(log(as.numeric(assay(brextern["BRCA2",])+1)), 
   brexp$histological_type), ylab="log BRCA2")
```

But there is a price to pay.
```{r domicr}
library(microbenchmark)
microbenchmark(
 split(log(as.numeric(assay(brextern["BRCA2", ]) + 1)), 
   brexp$histological_type),
 times=5)
```
Compare to the `in memory` benchmark:
```{r doinm}
microbenchmark(
 split(log(as.numeric(assay(brexp["BRCA2", ]) + 1)), 
   brexp$histological_type),
 times=5)
```

## Exercises with the HumanTranscriptomeCompendium and the HDF Scalable Data Service (10min)

The HumanTranscriptomeCompendium package was formed to take
advantage of two new technologies. 

The first is the 
[OmicIDX](https://omicidx-test.cancerdatasci.org/docs)
metadata transformation and access facility, devised
by Dr Sean Davis of NCI.
This currently provides comprehensive access to metadata
about sequencing studies collected at NCBI SRA, but will
be extended to other institutional metadata archives.

The second is HDF Scalable Data Service, devised by
John Readey of The HDF Group.  Substantial support has been
provided to Bioconductor by HDF Group, with open hosting
of significant genomic data archives in a publicly accessible
server.

Fruits of both of these developments are used in the following
exercises.

### Command-line work with HumanTranscriptomeCompendium

```{r lkhtc}
library(HumanTranscriptomeCompendium)
htxSE = htx_load()
htxSE
```

There's a little extra annotation to add.
```{r doadd}
htxSE = addRD(htxSE)
library(SummarizedExperiment)
head(rowData(htxSE))
```

We will make a searchable table of study titles and sizes.
```{r dozsi}
ad = as.data.frame(colData(htxSE))
library(dplyr)
library(magrittr)
library(DT)
studtab = (ad %>% select(study_title, study_accession) %>% group_by(study_title, study_accession) %>% summarise(n=n()) %>% as.data.frame()) 
datatable(studtab)
```

Search for zika in this table.
```{r lksub}
zikp = htxSE[, which(htxSE$study_accession == "SRP075248")]
assay(zikp)
```

To acquire additional metadata on this study, you could use SRAdbV2.  We
will skip that for now.

### The ca43k app

We have a shiny app that mediates access to cancer-related studies in the
compendium.  Using the following command starts the app.  Clear
the initial tabs and cart elements.  Search for the
string 'lncRNAs' and then search the resulting table for 'archived'.
Then stop the app.
```{r zz,eval=FALSE}
cadat = ca43k()
```
Now `metadata(cadat)[[2]]` is a data.frame that gives sample-level
metadata on the samples that were retrieved.  How many different
tissues were assayed?

Have a look at the paper referenced in the associated PMID.
Find the lncRNA that the authors assert is specific to breast
and display its distribution of abundance across tissues.

## Exercises with PanCancer Atlas and Google BigQuery (10min)

The PanCancer Atlas builds on TCGA by including a number
of matched normal tissue samples subjected to many of
the same assay processes as the tumor tissues.

In this section we'll create SummarizedExperiment
instances for 450k methylation assays in bladder cancer.

### Some background on PanCancer Atlas data in the ISB Cancer Genomics Cloud project

The names of resources available for PanCancer atlas
are somewhat unwieldy.  We've created abbreviations.
```{r lkbpc, results="hide"}
library(BiocOncoTK)
```
```{r chkanno}
anndf = data.frame(abbr=names(
  BiocOncoTK::annotTabs), tabname=as.character(BiocOncoTK::annotTabs))
datatable(anndf)
```

In this section you must have environment variable
`CGC_BILLING` set to a valid google cloud platform
billing account.

### Creating a 'RESTful' SummarizedExperiment with BigQuery references for assay data

```{r lkpc, results="hide", eval=FALSE}
library(BiocOncoTK)
bq = pancan_BQ()
bq@quiet = TRUE
se1 = buildPancanSE(bq)
```
```{r lkcanse, eval=FALSE}
se1

## class: RangedSummarizedExperiment 
## dim: 396065 409 
## metadata(3): acronym assay sampType
## assays(1): assay
## rownames(396065): cg00000029 cg00000165 ... rs966367 rs9839873
## rowData names(3): gene_id gene_name gene_biotype
## colnames(409): TCGA-FD-A3SN TCGA-FD-A5BV ... TCGA-UY-A78L
##   TCGA-ZF-AA4T
## colData names(20): bcr_patient_uuid bcr_patient_barcode ...
##   radiation_therapy race

```
```
assay(se1)

## <396065 x 409> DelayedMatrix object of type "double":
##            TCGA-FD-A3SN TCGA-FD-A5BV ... TCGA-UY-A78L TCGA-ZF-AA4T
## cg00000029    0.0954445    0.0687728   .     0.162314     0.172125
## cg00000165    0.8368510    0.1360180   .     0.623998     0.387653
## cg00000236    0.9393230    0.9227600   .     0.873759     0.904457
## cg00000289    0.7025300    0.7373440   .     0.641360     0.609875
## cg00000292    0.7530310    0.8062190   .     0.729177     0.505125
##        ...            .            .   .            .            .
##  rs9363764    0.9462190    0.9424980   .    0.4760480    0.0337384
##   rs939290    0.0228799    0.9769100   .    0.9669960    0.9753450
##   rs951295    0.3357700    0.0386658   .    0.5140070    0.7081640
##   rs966367    0.9464320    0.9492910   .    0.8572390    0.4777650
##  rs9839873    0.9548290    0.2012180   .    0.9278950    0.9552880
```

### Comparing methylation levels between tumor and matched normal tissues at a specific CpG probe

In PMID 29540343 it is noted that increased methylation at
CpG probe cg22748573 (within exon 1 of CITED4)
is associated with decreased risk
of bladder cancer.  We'll use tumor-normal pairs to
check for differential methylation in tumor tissue at 
this site.


```{r lkcpg, eval=FALSE}
nor = buildPancanSE(bq, sampType="NT")
nor
kp = intersect(colnames(nor), colnames(se1)) 
norsel = nor["cg22748573",kp]
se1sel = se1["cg22748573",kp]
nornum = as.matrix(assay(norsel))
se1num = as.matrix(assay(se1sel))
t.test(se1num-nornum)
plot(as.numeric(nornum), as.numeric(se1num), ylim=c(0,.5), xlim=c(0,.5))
abline(0,1)
```

## Docker and CWL/WDL with Dockstore.org (10min)

dockstore.org implements a GA4GH concept of reproducible
research by connecting a CWL/WDL workflow program to a
docker container that is endowed with everything needed
to execute the workflow.

An example workflow is available, that [annotates variants
observed in a given Coriell cell line sample]
(https://dockstore.org/workflows/github.com/vjcitn/vardemo/AnnotatingWGSVariantsWithBioc:master?tab=info).

### A WDL program

The main components are `workflow` and `task`.  Tasks are
called within the workflow element.  In this example
the task consists of a command, and declarations of
output and runtime.

```
workflow task1 {
  call doVariantWorkflow { }
}

task doVariantWorkflow {
  command {
    R -e "BiocManager::install('variants', version = '3.9', update=TRUE, ask=FALSE); \
		library('variants'); \
		file <- system.file('vcf', 'NA06985_17.vcf.gz', package = 'cgdv17'); \
		genesym <- 'ORMDL3'; \
		geneid <- select(org.Hs.eg.db, keys=genesym, keytype='SYMBOL', \
		         columns='ENTREZID'); \
		txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene; \
		seqlevelsStyle(txdb) = 'NCBI'; \
		txdb = keepStandardChromosomes(txdb); \
		txdb <- keepSeqlevels(txdb, '17'); \
		txbygene = transcriptsBy(txdb, 'gene'); \
		gnrng <- unlist(range(txbygene[geneid[['ENTREZID']]]), use.names=FALSE); \
		names(gnrng) <- geneid[['SYMBOL']]; \
		param <- ScanVcfParam(which = gnrng+20000, info = 'DP', geno = c('GT', 'cPd')); \
		vcf <- readVcf(file, 'hg19', param); \
		seqlevels(vcf)[25] = 'MT'; \
		ans = locateVariants(vcf, txdb, AllVariants()); \
		table(mcols(ans)[['LOCATION']]); \
		names(ans) = make.names(names(ans), unique=TRUE); \
		ans = as.data.frame(ans); \
		rownames(ans) = make.names(rownames(ans), unique=TRUE); \
                write.csv(ans, 'trpvar.csv');"
  }
  output {
      File out1 = "trpvar.csv"
  }
  runtime {
    disks: "local-disk 40 HDD"
    bootDiskSizeGb: 50
    docker: "waldronlab/bioconductor_devel"
    }
}
```

Note that the dockstore includes capacity to easily submit
the workflow to a hosted cloud computing service.

`r knitr::include_graphics(system.file(package='BiocCloudws', 'vignettes', 'button.png'))`

## Summary

We had two main concerns.  First, we reviewed the integrated
approach to genome-scale metadata and data representation exemplified
in `EnsDb`, `GRanges`, and `SummarizedExperiment` instances.
Second, we demonstrated how external data resources can be
connected to R-based analyses through these representations.
We showed how local HDF5 stores can be created and queried
through the utilities provided with the `HDF5Array` package.
We showed how remote HDF5 can be queried using `restfulSE`
concepts.  All of this proceeds without concern for authentication.

In our final sections, we indicated how Google BigQuery can
be used behind a SummarizedExperiment interface, and how the
combination of a Docker container and a WDL program
can be used to specify a reproducible (and potentially parameterized)
workflow project, which can be submitted for execution in a system
such as Terra or DNANexus.  These examples require attention
to authentication and billing setup.

We conclude that it is fruitful to think about unifying abstractions
for complex collections of genomic assays and annotation.  A good
example is the `MultiAssayExperiment` structure that is generated
very naturally with the `curatedTCGAData` package.  We can work such
structures without regard for the physical disposition of the
data, once protocols like `DelayedArray` are implemented for
alternative back-ends that we find productive for handling
numerical arrays or other fundamental data structures for genome-scale
analysis.
