---
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    toc_depth: 3
    fig_width: 5
bibliography: "`r file.path(system.file(package='Bioc2019CloudWkshop', 'vignettes'), 'cloudbioc.bib')`"
vignette: >
  %\VignetteIndexEntry{cloudBiocWorkshop}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding[utf8]{inputenc}
---
# Cloud-scale genomic data science with Bioconductor

## Abstract

Bioconductor's approach to the analysis of genome-scale assays is
rooted in commitments to the use of self-describing data objects 
representing genomic assays and annotation.  Analysis tools and workflows
based on these objects have proven effective in a large
number of scientific projects and publications.

The dominant model for utilization of Bioconductor to date 
involves a locally controlled deployment of R and 
Bioconductor/CRAN packages in an essentially closed
storage and execution environment.

New approaches to federated
elastic computing with lab-resident or commercial cloud
environments provide opportunities for inference on questions
of vast scope.  This workshop is devoted to understanding how
to leverage Bioconductor's strengths
in seizing these new opportunities.  Special attention is devoted
to how
programming and reporting
patterns familiar from two decades of Bioconductor development
and use can be retained, or must change, in cloud-scale genomic
data science.

Our approach will be a mix of lecture and hands-on programming
with Rstudio Cloud.  We will learn how the restfulSE and BiocOncoTK
packages work with HDF Scalable Data Service and Google BigQuery
to provide immediate interactive access to a compendium of 181000
human transcriptomics experiments, and to the PanCancer Atlas.
We will also learn how to couple Docker containers with formal
workflows in CWL and WDL to achieve sharable reproducible analyses
with nearly zero configuration.  

## Pre-requisites

* Basic knowledge of R syntax
* Familiarity with the SummarizedExperiment class
* Familiarity with one or more of TCGA, GTEx, BigQuery
* Familiarity with docker containers is not required but a running docker installation will be useful

## Workshop Participation

Students should have a laptop and be prepared to execute
specific commands to load packages and
evaluate functions.  It will be helpful to have a Google identity
that may be necessary to work with BigQuery.

## _R_ / _Bioconductor_ packages used

DelayedArray, restfulSE, rhdf5client, BiocOncoTK, 
htxcomp (github/vjcitn), TxRegInfra

## Time outline

Approximate timings for sections of workshop

| Activity                     | Time |
|------------------------------|------|
| Review of Bioconductor software and data structures | 10m  |
| DelayedArray concepts          | 5m  |
| Exercises with htxcomp and the HDF Scalable Data Service | 10m  |
| Exercises with PanCancer Atlas and Google BigQuery | 10m |
| Docker and CWL/WDL with Dockstore.org | 10m |

## Workshop goals and objectives

Goals:

* Develop an appreciation of strengths and limitations
of Bioconductor's approach
to structure and annotation of genome-scale data as scope
of data grows to cloud scale

* Learn about alternatives to "all-in-memory" models of
computing in R, and how Bioconductor has used such alternatives
in the local computing model
(e.g., external SQLite databases, local HDF5 serialization,
API to remote services)

* Obtain experience using Bioconductor
methods and tools with data and annotation that are cloud-scale

* Develop an appreciation of threats to reliability and predictable
costs that arise when working with commercial cloud computing

Objectives:

* Use rhdf5client to interact with matrix data in HDF Scalable Data Service

* Use BiocOncoTK to interrogate multiomic PanCancer atlas data in Google BigQuery

* Understand the role of Docker containers and formal workflow
expression in establishing reproducible and shareable large
scale analyses 

# Course activities

## Review of Bioconductor software and data structures (10min)

Bioconductor uses an approach to object-oriented
programming to help control complexity of programming
in the domain of genome-scale data science.

We will illustrate the basic ideas by using a
catalog of features of the human genome.

```{r setup,echo=FALSE,results="hide"}
library = function (...) 
{
libstats = function(inisess, newsess) {
 inibase = inisess$basePkgs  # unchanging?
 inioth = names(inisess$otherPkgs)
 newbase = newsess$basePkgs
 newoth = names(newsess$otherPkgs)
 iniatt = length(unique(c(inibase,inioth)))
 newatt = length(unique(c(newbase,newoth)))
 addatt = newatt-iniatt
 inilo = names(inisess$loadedOnly)
 newlo = names(newsess$loadedOnly)
 addlo = length(setdiff(newlo, inilo))
 c(addatt=addatt, addlo=addlo)
}
    inisess = sessionInfo()
    suppressPackageStartupMessages({
        libdata = base::library(...)
        newsess = sessionInfo()
        lstats = libstats(inisess = inisess, newsess = newsess)
        message(sprintf("%d/%d packages newly attached/loaded, see sessionInfo() for details.", 
            lstats["addatt"], lstats["addlo"]))
        invisible(NULL)
    })
}
```

### The S4 classes `EnsDb` and `GRanges`

```{r lktxdb}
library(EnsDb.Hsapiens.v79)
EnsDb.Hsapiens.v79
```

The object named `EnsDb.Hsapiens.v79` mediates access to
a SQLite database that contains information on the
Ensembl definitions of genes for reference build
hg38.  This object is an instance of a class:
```{r lkcl}
class(EnsDb.Hsapiens.v79)
```
Formal methods are defined for this class:
```{r lkme}
methods(class=class(EnsDb.Hsapiens.v79))
```
Let's try the `genes` method.
```{r lkggg}
genes79 = genes(EnsDb.Hsapiens.v79)
genome(genes79)[1]
class(genes79)
head(genes79[,1:3])
```

Basic R language elements are given new 
meaning when applied to structures like `GRanges`.
Here we use `$` to obtain one of the fields
of metadata about genes.  The operation returns
a vector that we summarize using basic R
functions.

```{r lkso}
sort(table(genes79$gene_biotype),decreasing=TRUE)[1:6]
```

`dplyr` idioms can be used with some help (and this may
become more straightforward over time):
```{r dodp}
library(dplyr)
library(magrittr)
as.data.frame(mcols(genes79)) %>% 
  select(gene_name, gene_biotype) %>%
  filter(gene_biotype == "ribozyme")
```

`tibble` representations have pleasant summaries:
```{r lkti}
library(tibble)
as.tibble(genes79)
```

### Finding and visualizing genomic elements in a specified chromosomal region

`GRanges` are easy to construct and can be used to
query genomes.  Here we deal with three problems related
to genome region specification.  We start with a
region specified using coordinates from
reference build hg19 (GRCh37).  We use UCSC's
liftOver utility to convert to GRCh38 (hg38).  We
finish by converting the chromosome annotation to
that used by Ensembl.

```{r convert}
myRange = GRanges("chr10", IRanges(37.45e6, 37.8e6))
myRange
library(rtracklayer)
ch = import.chain("hg19ToHg38.over.chain")
myr38 = liftOver(myRange, ch)[[1]]
library(GenomeInfoDb)
genome(myr38) = "GRCh38"
seqlevelsStyle(myr38) = "Ensembl"
myr38
```

It is easy to find 'gene-level' elements using `subsetByOverlaps`:
```{r getgl}
els = subsetByOverlaps(genes79, myr38)
as.tibble(els)
```

To get a quick view of the layout of these elements on
their chromosome, we can use Gviz:
```{r getgv}
library(Gviz)
options(ucscChromosomeNames=FALSE)
plotTracks(list(GenomeAxisTrack(), 
  GeneRegionTrack(els, gene=els$symbol)), showId=TRUE)
```

There are many options available to enhance this display.
An important task for this region would
be to distinguish exons and introns.
See the Gviz vignette for details.


## DelayedArray concepts (5min)

Our interest in cloud-scale computing methods
arises in part from desire to analyze very large
data sets with computers that have relatively small
endowments of random access memory.  The most common
methods of working with R assume that all data are
resident in memory and can be addressed directly.

### Acquisition of breast cancer RNA-seq data from TCGA

In this section we will construct two representations of
RNA-seq data for breast cancer tumors collected in TCGA.
First we use `curatedTCGAData` to obtain a standard in-memory
representation in a SummarizedExperiment.
```{r dobr, cache=TRUE}
library(curatedTCGAData)
brMAE = curatedTCGAData("BRCA", "RNASeq2GeneNorm", dry.run=FALSE)
brexp = experiments(brMAE)[[1]] # should use name
colnames(brexp) = substr(colnames(brexp),1,12) # need to shorten
cd = colData(brMAE)[colnames(brexp),]
colData(brexp) = cd
brexp
```
We estimate its size in RAM.
```{r lkram}
library(SummarizedExperiment) # assay
object.size(assay(brexp))
```
This is not particularly large, but in certain applications
it is advantageous to have tight control
over the memory consumption required for an analysis.  In
this form we have no choice -- either the complete dataset
is in memory or it is not and cannot be accessed without
loading it in its entirety.

### Exporting the expression data to HDF5

Now we develop a representation on disk.  We use
the HDF5 data format as it is well-established as
a tool for managing numerical data in
scientific computing.
```{r dohdf5}
library(HDF5Array)
saveHDF5SummarizedExperiment(brexp, "brexpHDF5", replace=TRUE)
```
We named the HDF5 repository for the data `brexpHDF5`; this 
is in fact a folder created in the current working directory.
Its contents are a SummarizedExperiment 'shell' in RDS format,
and the HDF5 matrix representation of the RNA-seq quantifications.
```{r lkfol}
dir("brexpHDF5")
```

### Using the on-disk HDF5 representation

We use a loading function to retrieve the
new SummarizedExperiment instance.  Its
memory consumption is independent of the
dimensions of the assay matrix.
```{r lkmem2}
brextern = loadHDF5SummarizedExperiment("brexpHDF5")
assay(brextern)
object.size(assay(brextern))
```

Targeted queries to the HDF5 store are rapidly resolved.

```{r doexpl,fig.height=6}
par(las=2, mar=c(18,4,3,3))
boxplot(split(log(as.numeric(assay(brextern["BRCA2",])+1)), 
   brexp$histological_type), ylab="log BRCA2")
```

But there is a price to pay.
```{r domicr}
library(microbenchmark)
microbenchmark(
 split(log(as.numeric(assay(brextern["BRCA2", ]) + 1)), 
   brexp$histological_type),
 times=5)
```
Compare to the `in memory` benchmark:
```{r doinm}
microbenchmark(
 split(log(as.numeric(assay(brexp["BRCA2", ]) + 1)), 
   brexp$histological_type),
 times=5)
```

## Exercises with the HumanTranscriptomeCompendium and the HDF Scalable Data Service (10min)

- Use htx_app or ca43k app

## Exercises with PanCancer Atlas and Google BigQuery (10min)

## Docker and CWL/WDL with Dockstore.org (10min)
